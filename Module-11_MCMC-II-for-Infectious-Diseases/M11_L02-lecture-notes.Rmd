---
title: "Module 11: Lesson 2 Lecture Notes"
author: "Callum Arnold"
date: "7/19/2021"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: true
header-includes:
  - \usepackage{cancel}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# SIR models

## The modelling process

## Gamma distribution example  {#gammadist}

-   Suppose we have data on incubation periods $y = y_1, …, y_n$ and we wish to
    fit a Gamma distribution to these data ($y_i$) is the incubation period for
    person $i$

-   The Gamma distribution has the probability density function

    -   $f(x|\alpha, \beta) = \beta^\alpha x^{\alpha -1} \exp(-\beta x) / \Gamma(\alpha) \quad \text{where } x>0, \alpha > 0, \beta > 0$

    -   We can write this proportionally as
        $f(x|\alpha, \beta) \propto x^{\alpha -1} \exp(-\beta x)$

-   Assume data are independent draws from this distribution, therefore the
    likelihood is:

$$
\begin{aligned}
\pi(y|\alpha, \beta) &= f(y_1 |\alpha, \beta) \times ... \times f(y_n |\alpha, \beta) \\
&= \beta^{n\alpha} \prod_k y_k^{\alpha -1} \exp(\beta \sum y_k) / \{\Gamma(\alpha)\}^n
\end{aligned}
$$

-   We assign independent priors as

    -   $\alpha \sim \text{Gamma}(\lambda_\alpha, v_\alpha) \\ \beta \sim \text{Gamma}(\lambda_\beta, v_\beta)$

        -   Use Gamma prior as:

            -   Flexible so can be very informative/uninformative as we wish

            -   Mathematical convenience - for $\beta$ in particularly, gives
                nice way of evaluation full conditional density

-   We can get the posterior density of interest

    -   $\pi(\alpha, \beta | y) \propto \pi(y|\alpha, \beta)\pi(\alpha)\pi(\beta)$

    -   Define MCMC algorithm to sample from this target density to update
        $\alpha$ and $\beta$

### Updating separately

-   Find the full conditional densities

    -   $\pi(\alpha | \beta, y)$ and $\pi(\beta | \alpha, y)$

    -   $\pi(\alpha | \beta, y)$ is only known up to proportionality

        -   Therefore have to update $\alpha$ using a Metropolis-Hastings step

        -   $p = \frac{\pi(y|\alpha^*, \beta)\pi(\alpha^*)q(\alpha | \alpha^*)}{\pi(y|\alpha, \beta)\pi(\alpha)q(\alpha^* | \alpha)}$

    -   $\pi(\beta | \alpha, y)$ is the density of a Gamma distribution

        -   Can update using a Gamma distribution

### Block update

-   Instead of updating separately, put them in a block and update together

-   Use M-H and propose $(\alpha^*, \beta^*)$ from
    $q(\alpha^*, \beta^*|\alpha, \beta)$ and accept/reject accordingly

-   May want to do if $\alpha$ and $\beta$ are strongly correlated

    -   Hard to move one without the other

## General (Markov) SIR example

-   Suppose we observe $n$ removals at times $r_1 \le r_2 \le ... \le r_n$

-   We want to estimate $\beta$ and $\gamma$

    -   Posterior density $\pi(\beta, \gamma|r_1, r_2, ..., r_n)$

-   The likelihood is very hard to compute

    -   $\pi(r_1, r_2, ..., r_n |\beta, \gamma)$

    -   Have to think about all possible ways removals could happen (don't know
        when infected, or the order of the events e.g. inf, inf, inf, rem, rem,
        rem etc.)

    -   Introduce infection times as extra variables to give tractable augmented
        likelihood

### Augmented likelihood

-   Let $b$ be the label of the last removal time i.e. $r_b \ge r_k$ for all
    $k=1, …, n$

-   Given removal data, $b$ is observed and fixed

-   Define $a$ as the label of the first infection time $i_a <i_k$ for all
    $k \ne a$

-   Given removal data, $a$ is unknown

-   Define:

    -   $\vec{r} = r_1, ..., r_n$

    -   $\vec{i} = i_1, ..., i_{a-1}, i_{a+1}, ..., i_n$

        -   Note that it does not include $i_a$, which is the time of infection
            for the first infected individual $a$

-   Let $f(x|\gamma) = \gamma \exp(-\gamma x) \quad x>0$

    -   Probability density function of the infectious period distribution
        ($\text{Exp}(\gamma)$)

-   The augmented likelihood:

$$
\begin{aligned}
\pi(\vec{i}, \vec{r}|\beta, \gamma, i_a, a) 
&= \prod_{j \ne a}\beta N^{-1}I(i_j-) \times \exp \left(-\beta N^{-1} \int S(t)I(t) dt\right) \times \prod_{1 \le j \le n} f(r_j - i_j |\gamma) \\
&= \underbrace{\prod_{j \ne a}\beta N^{-1}I(i_j-) \times \exp \left(-\beta N^{-1} \int S(t)I(t) dt\right)}_{\text{how likely that individuals get infected at inf times observed}} \times \underbrace{\gamma^n \exp\left(-\gamma \sum(r_j -i_j)\right)}_{\text{how likely to observe removals}}
\end{aligned}
$$

-   where $I(t-)$ means $I(t)$ **just before** time $t$
-   The first part of the augmented likelihood can be derived by looking at the
    times to next event distribution

$$
\begin{aligned}
T_i &\sim \text{Exp}(\beta SI/N + \gamma I) \\
p(inf) &= \frac{\beta SI/N }{\beta SI/N + \gamma I} \\
p(rem) &= \frac{\gamma I }{\beta SI/N + \gamma I} \\
\text{given } X &\sim \text{Exp}(\lambda) \to f(x) = \lambda \exp(-\lambda x) \\
f(T) &= \cancel{(\beta SI/N + \gamma I)} \exp(-(\beta SI/N + \gamma I)(i_2 - i_1)) \times \frac{\beta SI/N }{\cancel{\beta SI/N + \gamma I}} \\
f(T) &= \exp(-(\beta SI/N + \gamma I)(i_2 - i_1)) \times \beta SI/N
\end{aligned}
$$

-   This represents the likelihood that the next event after $i_1$ is an
    infection and occurs at time $i_2$

    -   This can be multiplied for all successive infection event times, which
        gives the product term

    -   The term $(i_2 - i_1)$ is specifying the time until the infection

    -   $(\beta SI/N + \gamma I) \exp(-(\beta SI/N + \gamma I)$ is how likely it
        is to draw the time $i_2-i_1$ from the exponential infection time
        distribution

    -   $\frac{\beta SI/N}{\beta SI/N + \gamma I}$ is the likelihood that the
        event is an infection, if an infection was drawn

        -   If the next event was a removal, the final term would instead be
            $\frac{\gamma I}{\beta SI/N + \gamma I}$ and we would instead have
            $(r_1 - i_1)$

    -   The integral symbol comes because we are actually calculating the area
        when multiplying $\beta SI/N$ in the exponential by the time difference
        $(i_2 - i_1)$

        ![](images/Screen%20Shot%202021-07-19%20at%209.27.08%20PM.png)

-   There's an analogous one for the removal times

-   **NB:** $S$ and $I$ refer to the numbers in the respective compartments at
    time $t$

    -   We end up dropping the $S$ and $I$ terms due to the differences between
        the simulation and calculating the likelihood

        -   The simulation describes the number of susceptibles and the number
            of infecteds

        -   Calculating the likelihood, we label the individuals already e.g.
            when infection occurs, we say it's a particular individual who gets
            infected

            -   Results in slight difference

-   The target posterior density
    $\pi(\beta, \gamma, \vec{i}, i_a, a | \vec{r}) \propto \pi(\vec{i}, \vec{r}| \beta, \gamma, i_a, a)\pi(\beta, \gamma, i_a, a)$

    -   Define independent priors

$$
\begin{aligned}
\alpha &\sim \text{Gamma}(\lambda_\alpha, \nu_\alpha) \\ 
\beta &\sim \text{Gamma}(\lambda_\beta, \nu_\beta) \\ 
a &\sim \text{U}[1, n] \\ 
i_a &\sim \text{U}[-\infty, r_1]
\end{aligned}
$$

-   **NB:** we know the first infection must happen before the first removal,
    but we don't know exactly when, hence $\text{U}[-\infty, r_1]$

-   If we can find the first full conditional distribution, we can update using
    that if it's a standard distribution, and use MH if not

    -   We know the posterior for $\beta$ is a Gamma distribution, which we can
        sample from

        -   Sampling directly from the full conditional distribution is often
            called the **Gibbs step**

        -   $\gamma$ posterior is also Gamma distribution

        -   We can show this in the following steps

First let's compute the full joint density function up to proportionality. To do
this, we will use Bayes' theorem, and the specification of the likelihood
$\pi(y|\alpha, \beta)$, which stems from the probability density function of the
Gamma distribution (see [Section 1](\#gammadist)). From here, we can multiply
the likelihood by the prior (a Gamma distribution specified above), to get the
posterior (up to proportionality).

$$
\begin{aligned}
\pi(\alpha, \beta | y) &\propto 
\pi(y|\beta, ...)\cancel{\pi(\alpha)}\pi(\beta) \\
\pi(y| \alpha, \beta) 
&\propto \prod_{j \ne a} \frac{\beta}{N} I(i_j-) e^{-\frac{\beta}{N}\int S(t)I(t) dt} \gamma^n e^{-\gamma \sum(r_j - i_j)} \\
\pi(\alpha, \beta | y) 
&\propto \prod_{j \ne a} \frac{\beta}{\cancel{N}} \cancel{I(i_j-)} e^{-\frac{\beta}{N}\int S(t)I(t) dt} \cancel{\gamma^n e^{-\gamma \sum(r_j - i_j)}} \times \cancel{\frac{\nu_\beta^{\lambda_\beta}}{\Gamma(\lambda_\beta)}}\beta^{\lambda_\beta -1}e^{-\nu_\beta \beta}\\
&\propto \beta^n e^{-\frac{\beta}{N}\int S(t)I(t) dt} \times \beta^{\lambda_\beta -1}e^{-\nu_\beta \beta} \\
&\propto \beta^{n+\lambda_\beta - 1} e^{-\beta \left(\frac{1}{N}\int S(t)I(t) dt + \nu_\beta\right)} \\
&\therefore \\
f(\beta| ...) &\sim \Gamma\left(n+\lambda_\beta -1, \frac{1}{N}\int S(t)I(t) dt + \nu_\beta\ \right)
\end{aligned}
$$

-   For the infection times, the full conditional is non-standard

    -   Update using M-H algorithm with M-H acceptance ratio

        -   We're really mainly interested in $\beta$ and $\gamma$, so may just
            want to update 10% of the infection times between each update of
            $\beta$ and $\gamma$, otherwise may be too much computational work

        -   ratio of the likelihood \* ratio of proposal densities

        -   **Note:** If $i_k^* < i_a$ then $a^*=k$, otherwise $a$ is unchanged
            (first infected individual)

    -   How to propose infection times

        -   Must be before removal time

        -   Multiple options:

            -   $i_k^* = r_k -\text{Exp}(\gamma)$

            -   $i_k^* = r_k -\text{Exp}(\mu)$ where $\mu$ is fixed

            -   $i_k^* \sim \mathcal{N}(i_k, \sigma^2)$

    -   Evaluating the likelihood

        -   $\pi(\vec{i}, \vec{r}|\beta, \gamma, i_a, a) = \prod_{j \ne a}\beta N^{-1}I(i_j-) \times \exp \left(-\beta N^{-1} \int S(t)I(t) dt\right) \times \gamma^n \exp\left(-\gamma \sum(r_j -i_j)\right)$

        -   The product term and the integral term are the difficult parts to
            evaluate
